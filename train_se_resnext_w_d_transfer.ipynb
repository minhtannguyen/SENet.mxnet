{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse,logging,os\n",
    "import mxnet as mx\n",
    "from symbol_se_resnext_w_d_maxmin_transfer import resnext\n",
    "\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.gpus = '4,5,6,7' #the gpus will be used, e.g \"0,1,2,3\"\n",
    "        self.data_dir = '/tanData/datasets/imagenet/data/imagenet_senet' #the input data directory\n",
    "        self.data_type = 'imagenet' #the dataset type\n",
    "        self.depth = 50 #the depth of resnet\n",
    "        self.batch_size = 192 #the batch size\n",
    "        self.num_group = 64 #the number of convolution groups\n",
    "        self.drop_out = 0.0 #the probability of an element to be zeroed\n",
    "        self.pretrained_model = '/root/repos/SENet.mxnet/pretrained_models/se-resnext-imagenet-50-0' \n",
    "        \n",
    "        self.list_dir = './' #the directory which contain the training list file\n",
    "        self.lr = 0.01 #initialization learning rate\n",
    "        self.mom = 0.9 #momentum for sgd\n",
    "        self.bn_mom = 0.9 #momentum for batch normlization\n",
    "        self.wd = 0.0001 #weight decay for sgd\n",
    "        self.workspace = 512 #memory space size(MB) used in convolution, \n",
    "                            #if xpu memory is oom, then you can try smaller vale, such as --workspace 256 \n",
    "        self.num_classes = 1000 #the class number of your task\n",
    "        self.aug_level = 2 # level 1: use only random crop and random mirror, \n",
    "                           #level 2: add scale/aspect/hsv augmentation based on level 1, \n",
    "                           #level 3: add rotation/shear augmentation based on level 2 \n",
    "        self.num_examples = 1281167 # the number of training examples\n",
    "        self.kv_store = 'device' # the kvstore type'\n",
    "        self.model_load_epoch = 125 # load the model on an epoch using the model-load-prefix\n",
    "        self.frequent = 50 # frequency of logging\n",
    "        self.memonger = False # true means using memonger to save momory, https://github.com/dmlc/mxnet-memonger\n",
    "        self.retrain = False # true means continue training\n",
    "        \n",
    "args = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-02 09:10:26,023 - <__main__.Options object at 0x7efdf47b87f0>\n"
     ]
    }
   ],
   "source": [
    "hdlr = logging.FileHandler('./log/log-se-resnext-wpretrain-{}-{}.log'.format(args.data_type, args.depth))\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1):\n",
    "    step_ = [epoch_size * (x-begin_epoch) for x in step if x-begin_epoch > 0]\n",
    "    return mx.lr_scheduler.MultiFactorScheduler(step=step_, factor=factor) if len(step_) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list = [0.25, 0.125, 0.0625, 0.03125]   # 1/4, 1/8, 1/16, 1/32\n",
    "if args.data_type == \"cifar10\":\n",
    "    args.aug_level = 1\n",
    "    args.num_classes = 10\n",
    "    # depth should be one of 110, 164, 1001,...,which is should fit (args.depth-2)%9 == 0\n",
    "    if((args.depth-2)%9 == 0 and args.depth >= 164):\n",
    "        per_unit = [(args.depth-2)/9]\n",
    "        filter_list = [16, 64, 128, 256]\n",
    "        bottle_neck = True\n",
    "    elif((args.depth-2)%6 == 0 and args.depth < 164):\n",
    "        per_unit = [(args.depth-2)/6]\n",
    "        filter_list = [16, 16, 32, 64]\n",
    "        bottle_neck = False\n",
    "    else:\n",
    "        raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(args.depth))\n",
    "    units = per_unit*3\n",
    "    symbol = resnext(units=units, num_stage=3, filter_list=filter_list, ratio_list=ratio_list, num_class=args.num_classes, num_group=args.num_group,\n",
    "                    data_type=\"cifar10\", drop_out=args.drop_out, bottle_neck = bottle_neck, bn_mom=args.bn_mom, workspace=args.workspace,\n",
    "                    memonger=args.memonger)\n",
    "elif args.data_type == \"imagenet\":\n",
    "    args.num_classes = 1000\n",
    "    if args.depth == 18:\n",
    "        units = [2, 2, 2, 2]\n",
    "    elif args.depth == 34:\n",
    "        units = [3, 4, 6, 3]\n",
    "    elif args.depth == 50:\n",
    "        units = [3, 4, 6, 3]\n",
    "    elif args.depth == 101:\n",
    "        units = [3, 4, 23, 3]\n",
    "    elif args.depth == 152:\n",
    "        units = [3, 8, 36, 3]\n",
    "    elif args.depth == 200:\n",
    "        units = [3, 24, 36, 3]\n",
    "    elif args.depth == 269:\n",
    "        units = [3, 30, 48, 8]\n",
    "    else:\n",
    "        raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(args.depth))\n",
    "    symbol = resnext(units=units, num_stage=4, filter_list=[64, 256, 512, 1024, 2048] if args.depth >=50\n",
    "                    else [64, 64, 128, 256, 512], ratio_list=ratio_list, num_class=args.num_classes, num_group=args.num_group, data_type=\"imagenet\", drop_out=args.drop_out, bottle_neck = True\n",
    "                    if args.depth >= 50 else False, bn_mom=args.bn_mom, workspace=args.workspace,\n",
    "                    memonger=args.memonger)\n",
    "\n",
    "else:\n",
    "     raise ValueError(\"do not support {} yet\".format(args.data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: `Tracer` is deprecated since version 5.1, directly use `IPython.core.debugger.Pdb.set_trace()`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/debugger.py:168: DeprecationWarning: The `color_scheme` argument is deprecated since version 5.1\n",
      "  self.debugger = Pdb(colors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> \u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/displayhook.py\u001b[0m(247)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    245 \u001b[0;31m        \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 247 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    248 \u001b[0;31m        \"\"\"Printing with history cache management.\n",
      "\u001b[0m\u001b[0;32m    249 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "Exiting Debugger.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:1736: DeprecationWarning: `BdbQuit_IPython_excepthook` is deprecated since version 5.1\n",
      "  stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n"
     ]
    }
   ],
   "source": [
    "mx.viz.plot_network(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = mx.kvstore.create(args.kv_store)\n",
    "devs = mx.cpu() if args.gpus is None else [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "epoch_size = max(int(args.num_examples / args.batch_size / kv.num_workers), 1)\n",
    "begin_epoch = 0\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.mkdir(\"./model\")\n",
    "model_prefix = \"model/se-resnext-wpretrain-{}-{}-{}\".format(args.data_type, args.depth, kv.rank)\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "pt_model, arg_params, aux_params = mx.model.load_checkpoint(args.pretrained_model, args.model_load_epoch)\n",
    "if args.memonger:\n",
    "    import memonger\n",
    "    symbol = memonger.search_plan(symbol, data=(args.batch_size, 3, 32, 32) if args.data_type==\"cifar10\"\n",
    "                                                else (args.batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"train.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"train_256_q90.rec\") if args.aug_level == 1\n",
    "                          else os.path.join(args.data_dir, \"train_480_q90.rec\") ,\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    batch_size          = args.batch_size,\n",
    "    pad                 = 4 if args.data_type == \"cifar10\" else 0,\n",
    "    fill_value          = 127,  # only used when pad is valid\n",
    "    rand_crop           = True,\n",
    "    max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "    min_random_scale    = 1.0 if args.data_type == \"cifar10\" else 1.0 if args.aug_level == 1 else 0.533,  # 256.0/480.0=0.533, 256.0/384.0=0.667 256.0/256=1.0\n",
    "    max_aspect_ratio    = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 0.25, # 0.25\n",
    "    random_h            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 36,  # 0.4*90\n",
    "    random_s            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    random_l            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    max_rotate_angle    = 0 if args.aug_level <= 2 else 10,\n",
    "    max_shear_ratio     = 0 if args.aug_level <= 2 else 0.0, #0.1 args.aug_level = 3\n",
    "    rand_mirror         = True,\n",
    "    shuffle             = True,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)\n",
    "val = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"val.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"val_256_q90.rec\"),\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    batch_size          = args.batch_size,\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    rand_crop           = False,\n",
    "    rand_mirror         = False,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sch = multi_factor_scheduler(begin_epoch, epoch_size, step=[220, 260, 280], factor=0.1) if args.data_type=='cifar10' else multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1)\n",
    "model = mx.mod.Module(\n",
    "    symbol = symbol,\n",
    "    context = devs,\n",
    "    data_names =  ['data'],\n",
    "    label_names = ['softmax_label']\n",
    ")\n",
    "#model.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "#model.init_optimizer(optimizer='nag', optimizer_params={'learning_rate':args.lr, 'momentum':args.mom, 'wd':args.wd, 'lr_scheduler': lr_sch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data         = train,\n",
    "    eval_data          = val,\n",
    "    eval_metric        = ['acc'] if args.data_type=='cifar10' else\n",
    "                         ['acc', mx.metric.create('top_k_accuracy', top_k = 5)],\n",
    "    kvstore            = kv,\n",
    "    batch_end_callback = mx.callback.Speedometer(args.batch_size, args.frequent),\n",
    "    epoch_end_callback = checkpoint,\n",
    "    num_epoch          = 200 if args.data_type == \"cifar10\" else 125,\n",
    "    begin_epoch        = 0,\n",
    "    arg_params         = arg_params,\n",
    "    aux_params         = aux_params,\n",
    "    allow_missing      =True,\n",
    "    optimizer          ='nag',\n",
    "    optimizer_params   ={'learning_rate':args.lr, 'momentum':args.mom, 'wd':args.wd, 'lr_scheduler': lr_sch}\n",
    ")\n",
    "# logging.info(\"top-1 and top-5 acc is {}\".format(model.score(X = val,\n",
    "#               eval_metric = ['acc', mx.metric.create('top_k_accuracy', top_k = 5)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
