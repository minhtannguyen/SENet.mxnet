{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse,logging,os\n",
    "import mxnet as mx\n",
    "from symbol_se_resnext_w_d_maxmin_transfer import resnext\n",
    "\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.gpus = '4,5,6,7' #the gpus will be used, e.g \"0,1,2,3\"\n",
    "        self.data_dir = '/tanData/datasets/imagenet/data/imagenet_senet' #the input data directory\n",
    "        self.data_type = 'imagenet' #the dataset type\n",
    "        self.depth = 50 #the depth of resnet\n",
    "        self.batch_size = 256 #the batch size\n",
    "        self.num_group = 64 #the number of convolution groups\n",
    "        self.drop_out = 0.0 #the probability of an element to be zeroed\n",
    "        self.pretrained_model = '/root/repos/SENet.mxnet/pretrained_models/se-resnext-imagenet-50-0' \n",
    "        \n",
    "        self.list_dir = './' #the directory which contain the training list file\n",
    "        self.lr = 0.00 #initialization learning rate\n",
    "        self.mom = 0.00 #momentum for sgd\n",
    "        self.bn_mom = 0.9 #momentum for batch normlization\n",
    "        self.wd = 0.00 #weight decay for sgd\n",
    "        self.workspace = 512 #memory space size(MB) used in convolution, \n",
    "                            #if xpu memory is oom, then you can try smaller vale, such as --workspace 256 \n",
    "        self.num_classes = 1000 #the class number of your task\n",
    "        self.aug_level = 2 # level 1: use only random crop and random mirror, \n",
    "                           #level 2: add scale/aspect/hsv augmentation based on level 1, \n",
    "                           #level 3: add rotation/shear augmentation based on level 2 \n",
    "        self.num_examples = 1281167 # the number of training examples\n",
    "        self.kv_store = 'device' # the kvstore type'\n",
    "        self.model_load_epoch = 125 # load the model on an epoch using the model-load-prefix\n",
    "        self.frequent = 50 # frequency of logging\n",
    "        self.memonger = False # true means using memonger to save momory, https://github.com/dmlc/mxnet-memonger\n",
    "        self.retrain = False # true means continue training\n",
    "        \n",
    "args = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 07:25:53,867 - <__main__.Options object at 0x7fe1a4698860>\n"
     ]
    }
   ],
   "source": [
    "hdlr = logging.FileHandler('./log/log-se-resnext-wpretrain-{}-{}.log'.format(args.data_type, args.depth))\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1):\n",
    "    step_ = [epoch_size * (x-begin_epoch) for x in step if x-begin_epoch > 0]\n",
    "    return mx.lr_scheduler.MultiFactorScheduler(step=step_, factor=factor) if len(step_) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list = [0.25, 0.125, 0.0625, 0.03125]   # 1/4, 1/8, 1/16, 1/32\n",
    "if args.data_type == \"cifar10\":\n",
    "    args.aug_level = 1\n",
    "    args.num_classes = 10\n",
    "    # depth should be one of 110, 164, 1001,...,which is should fit (args.depth-2)%9 == 0\n",
    "    if((args.depth-2)%9 == 0 and args.depth >= 164):\n",
    "        per_unit = [(args.depth-2)/9]\n",
    "        filter_list = [16, 64, 128, 256]\n",
    "        bottle_neck = True\n",
    "    elif((args.depth-2)%6 == 0 and args.depth < 164):\n",
    "        per_unit = [(args.depth-2)/6]\n",
    "        filter_list = [16, 16, 32, 64]\n",
    "        bottle_neck = False\n",
    "    else:\n",
    "        raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(args.depth))\n",
    "    units = per_unit*3\n",
    "    symbol = resnext(units=units, num_stage=3, filter_list=filter_list, ratio_list=ratio_list, num_class=args.num_classes, num_group=args.num_group,\n",
    "                    data_type=\"cifar10\", drop_out=args.drop_out, bottle_neck = bottle_neck, bn_mom=args.bn_mom, workspace=args.workspace,\n",
    "                    memonger=args.memonger)\n",
    "elif args.data_type == \"imagenet\":\n",
    "    args.num_classes = 1000\n",
    "    if args.depth == 18:\n",
    "        units = [2, 2, 2, 2]\n",
    "    elif args.depth == 34:\n",
    "        units = [3, 4, 6, 3]\n",
    "    elif args.depth == 50:\n",
    "        units = [3, 4, 6, 3]\n",
    "    elif args.depth == 101:\n",
    "        units = [3, 4, 23, 3]\n",
    "    elif args.depth == 152:\n",
    "        units = [3, 8, 36, 3]\n",
    "    elif args.depth == 200:\n",
    "        units = [3, 24, 36, 3]\n",
    "    elif args.depth == 269:\n",
    "        units = [3, 30, 48, 8]\n",
    "    else:\n",
    "        raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(args.depth))\n",
    "    symbol = resnext(units=units, num_stage=4, filter_list=[64, 256, 512, 1024, 2048] if args.depth >=50\n",
    "                    else [64, 64, 128, 256, 512], ratio_list=ratio_list, num_class=args.num_classes, num_group=args.num_group, data_type=\"imagenet\", drop_out=args.drop_out, bottle_neck = True\n",
    "                    if args.depth >= 50 else False, bn_mom=args.bn_mom, workspace=args.workspace,\n",
    "                    memonger=args.memonger)\n",
    "\n",
    "else:\n",
    "     raise ValueError(\"do not support {} yet\".format(args.data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx.viz.plot_network(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = mx.kvstore.create(args.kv_store)\n",
    "devs = mx.cpu() if args.gpus is None else [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "epoch_size = max(int(args.num_examples / args.batch_size / kv.num_workers), 1)\n",
    "begin_epoch = 0\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.mkdir(\"./model\")\n",
    "model_prefix = \"model/se-resnext-wpretrain-{}-{}-{}\".format(args.data_type, args.depth, kv.rank)\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "pt_model, arg_params, aux_params = mx.model.load_checkpoint(args.pretrained_model, args.model_load_epoch)\n",
    "if args.memonger:\n",
    "    import memonger\n",
    "    symbol = memonger.search_plan(symbol, data=(args.batch_size, 3, 32, 32) if args.data_type==\"cifar10\"\n",
    "                                                else (args.batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"train.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"train_256_q90.rec\") if args.aug_level == 1\n",
    "                          else os.path.join(args.data_dir, \"train_480_q90.rec\") ,\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    batch_size          = args.batch_size,\n",
    "    pad                 = 4 if args.data_type == \"cifar10\" else 0,\n",
    "    fill_value          = 127,  # only used when pad is valid\n",
    "    rand_crop           = True,\n",
    "    max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "    min_random_scale    = 1.0 if args.data_type == \"cifar10\" else 1.0 if args.aug_level == 1 else 0.533,  # 256.0/480.0=0.533, 256.0/384.0=0.667 256.0/256=1.0\n",
    "    max_aspect_ratio    = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 0.25, # 0.25\n",
    "    random_h            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 36,  # 0.4*90\n",
    "    random_s            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    random_l            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    max_rotate_angle    = 0 if args.aug_level <= 2 else 10,\n",
    "    max_shear_ratio     = 0 if args.aug_level <= 2 else 0.0, #0.1 args.aug_level = 3\n",
    "    rand_mirror         = True,\n",
    "    shuffle             = True,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)\n",
    "val = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"val.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"val_256_q90.rec\"),\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    batch_size          = args.batch_size,\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    rand_crop           = False,\n",
    "    rand_mirror         = False,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sch = multi_factor_scheduler(begin_epoch, epoch_size, step=[220, 260, 280], factor=0.1) if args.data_type=='cifar10' else multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1)\n",
    "model = mx.mod.Module(\n",
    "    symbol = symbol,\n",
    "    context = devs,\n",
    "    data_names =  ['data'],\n",
    "    label_names = ['softmax_label']\n",
    ")\n",
    "#model.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "#model.init_optimizer(optimizer='nag', optimizer_params={'learning_rate':args.lr, 'momentum':args.mom, 'wd':args.wd, 'lr_scheduler': lr_sch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 07:26:43,735 - Epoch[0] Batch [50]\tSpeed: 458.74 samples/sec\taccuracy=0.755132\ttop_k_accuracy_5=0.905331\n",
      "2018-09-10 07:27:11,771 - Epoch[0] Batch [100]\tSpeed: 456.71 samples/sec\taccuracy=0.763281\ttop_k_accuracy_5=0.915000\n",
      "2018-09-10 07:27:39,709 - Epoch[0] Batch [150]\tSpeed: 458.33 samples/sec\taccuracy=0.749297\ttop_k_accuracy_5=0.907891\n",
      "2018-09-10 07:28:07,614 - Epoch[0] Batch [200]\tSpeed: 458.83 samples/sec\taccuracy=0.762969\ttop_k_accuracy_5=0.909687\n",
      "2018-09-10 07:28:35,486 - Epoch[0] Batch [250]\tSpeed: 459.41 samples/sec\taccuracy=0.761484\ttop_k_accuracy_5=0.910781\n",
      "2018-09-10 07:29:03,272 - Epoch[0] Batch [300]\tSpeed: 460.72 samples/sec\taccuracy=0.757812\ttop_k_accuracy_5=0.907969\n",
      "2018-09-10 07:29:31,135 - Epoch[0] Batch [350]\tSpeed: 459.48 samples/sec\taccuracy=0.749844\ttop_k_accuracy_5=0.903984\n",
      "2018-09-10 07:29:59,061 - Epoch[0] Batch [400]\tSpeed: 458.41 samples/sec\taccuracy=0.760234\ttop_k_accuracy_5=0.903828\n",
      "2018-09-10 07:30:26,987 - Epoch[0] Batch [450]\tSpeed: 458.43 samples/sec\taccuracy=0.753672\ttop_k_accuracy_5=0.910234\n",
      "2018-09-10 07:30:54,912 - Epoch[0] Batch [500]\tSpeed: 458.43 samples/sec\taccuracy=0.757109\ttop_k_accuracy_5=0.908828\n",
      "2018-09-10 07:31:22,801 - Epoch[0] Batch [550]\tSpeed: 459.02 samples/sec\taccuracy=0.762031\ttop_k_accuracy_5=0.908281\n",
      "2018-09-10 07:31:50,741 - Epoch[0] Batch [600]\tSpeed: 458.18 samples/sec\taccuracy=0.754531\ttop_k_accuracy_5=0.907891\n",
      "2018-09-10 07:32:18,646 - Epoch[0] Batch [650]\tSpeed: 458.79 samples/sec\taccuracy=0.760000\ttop_k_accuracy_5=0.911719\n",
      "2018-09-10 07:32:46,557 - Epoch[0] Batch [700]\tSpeed: 458.66 samples/sec\taccuracy=0.764609\ttop_k_accuracy_5=0.908672\n",
      "2018-09-10 07:33:14,474 - Epoch[0] Batch [750]\tSpeed: 458.57 samples/sec\taccuracy=0.755703\ttop_k_accuracy_5=0.908125\n",
      "2018-09-10 07:33:42,341 - Epoch[0] Batch [800]\tSpeed: 459.37 samples/sec\taccuracy=0.755000\ttop_k_accuracy_5=0.906563\n",
      "2018-09-10 07:34:10,161 - Epoch[0] Batch [850]\tSpeed: 460.16 samples/sec\taccuracy=0.764375\ttop_k_accuracy_5=0.905625\n",
      "2018-09-10 07:34:38,040 - Epoch[0] Batch [900]\tSpeed: 459.19 samples/sec\taccuracy=0.754844\ttop_k_accuracy_5=0.911953\n",
      "2018-09-10 07:35:05,860 - Epoch[0] Batch [950]\tSpeed: 460.16 samples/sec\taccuracy=0.758047\ttop_k_accuracy_5=0.909219\n",
      "2018-09-10 07:35:33,667 - Epoch[0] Batch [1000]\tSpeed: 460.38 samples/sec\taccuracy=0.761406\ttop_k_accuracy_5=0.910312\n",
      "2018-09-10 07:36:01,562 - Epoch[0] Batch [1050]\tSpeed: 458.92 samples/sec\taccuracy=0.758516\ttop_k_accuracy_5=0.912344\n",
      "2018-09-10 07:36:29,434 - Epoch[0] Batch [1100]\tSpeed: 459.34 samples/sec\taccuracy=0.754375\ttop_k_accuracy_5=0.908359\n",
      "2018-09-10 07:36:57,405 - Epoch[0] Batch [1150]\tSpeed: 457.67 samples/sec\taccuracy=0.755859\ttop_k_accuracy_5=0.910078\n",
      "2018-09-10 07:37:25,317 - Epoch[0] Batch [1200]\tSpeed: 458.67 samples/sec\taccuracy=0.761016\ttop_k_accuracy_5=0.910391\n",
      "2018-09-10 07:37:53,218 - Epoch[0] Batch [1250]\tSpeed: 458.83 samples/sec\taccuracy=0.765391\ttop_k_accuracy_5=0.911172\n",
      "2018-09-10 07:38:21,106 - Epoch[0] Batch [1300]\tSpeed: 459.02 samples/sec\taccuracy=0.758516\ttop_k_accuracy_5=0.906953\n",
      "2018-09-10 07:38:48,998 - Epoch[0] Batch [1350]\tSpeed: 458.99 samples/sec\taccuracy=0.760391\ttop_k_accuracy_5=0.912266\n",
      "2018-09-10 07:39:16,908 - Epoch[0] Batch [1400]\tSpeed: 458.69 samples/sec\taccuracy=0.757109\ttop_k_accuracy_5=0.906406\n",
      "2018-09-10 07:39:44,853 - Epoch[0] Batch [1450]\tSpeed: 458.11 samples/sec\taccuracy=0.762578\ttop_k_accuracy_5=0.912734\n",
      "2018-09-10 07:40:12,798 - Epoch[0] Batch [1500]\tSpeed: 458.09 samples/sec\taccuracy=0.756563\ttop_k_accuracy_5=0.909219\n",
      "2018-09-10 07:40:40,701 - Epoch[0] Batch [1550]\tSpeed: 458.81 samples/sec\taccuracy=0.761719\ttop_k_accuracy_5=0.911016\n",
      "2018-09-10 07:41:08,570 - Epoch[0] Batch [1600]\tSpeed: 459.36 samples/sec\taccuracy=0.752344\ttop_k_accuracy_5=0.909609\n",
      "2018-09-10 07:41:36,474 - Epoch[0] Batch [1650]\tSpeed: 458.78 samples/sec\taccuracy=0.750078\ttop_k_accuracy_5=0.906250\n",
      "2018-09-10 07:42:04,408 - Epoch[0] Batch [1700]\tSpeed: 458.28 samples/sec\taccuracy=0.753984\ttop_k_accuracy_5=0.909219\n",
      "2018-09-10 07:42:32,363 - Epoch[0] Batch [1750]\tSpeed: 457.94 samples/sec\taccuracy=0.759062\ttop_k_accuracy_5=0.906563\n",
      "2018-09-10 07:43:00,314 - Epoch[0] Batch [1800]\tSpeed: 458.02 samples/sec\taccuracy=0.757422\ttop_k_accuracy_5=0.906797\n",
      "2018-09-10 07:43:28,268 - Epoch[0] Batch [1850]\tSpeed: 457.96 samples/sec\taccuracy=0.756250\ttop_k_accuracy_5=0.909609\n",
      "2018-09-10 07:43:56,101 - Epoch[0] Batch [1900]\tSpeed: 459.96 samples/sec\taccuracy=0.764766\ttop_k_accuracy_5=0.910859\n",
      "2018-09-10 07:44:23,911 - Epoch[0] Batch [1950]\tSpeed: 460.36 samples/sec\taccuracy=0.754531\ttop_k_accuracy_5=0.909375\n",
      "2018-09-10 07:44:51,775 - Epoch[0] Batch [2000]\tSpeed: 459.44 samples/sec\taccuracy=0.762500\ttop_k_accuracy_5=0.907891\n",
      "2018-09-10 07:45:19,674 - Epoch[0] Batch [2050]\tSpeed: 458.85 samples/sec\taccuracy=0.759687\ttop_k_accuracy_5=0.909375\n",
      "2018-09-10 07:45:47,572 - Epoch[0] Batch [2100]\tSpeed: 458.87 samples/sec\taccuracy=0.749297\ttop_k_accuracy_5=0.903906\n",
      "2018-09-10 07:46:15,439 - Epoch[0] Batch [2150]\tSpeed: 459.40 samples/sec\taccuracy=0.753359\ttop_k_accuracy_5=0.909375\n",
      "2018-09-10 07:46:43,267 - Epoch[0] Batch [2200]\tSpeed: 460.04 samples/sec\taccuracy=0.762500\ttop_k_accuracy_5=0.909062\n",
      "2018-09-10 07:47:11,164 - Epoch[0] Batch [2250]\tSpeed: 458.92 samples/sec\taccuracy=0.754375\ttop_k_accuracy_5=0.908125\n",
      "2018-09-10 07:47:39,018 - Epoch[0] Batch [2300]\tSpeed: 459.61 samples/sec\taccuracy=0.761328\ttop_k_accuracy_5=0.907109\n",
      "2018-09-10 07:48:06,903 - Epoch[0] Batch [2350]\tSpeed: 459.08 samples/sec\taccuracy=0.763594\ttop_k_accuracy_5=0.910078\n",
      "2018-09-10 07:48:34,753 - Epoch[0] Batch [2400]\tSpeed: 459.68 samples/sec\taccuracy=0.767734\ttop_k_accuracy_5=0.915078\n",
      "2018-09-10 07:49:02,665 - Epoch[0] Batch [2450]\tSpeed: 458.64 samples/sec\taccuracy=0.761484\ttop_k_accuracy_5=0.912891\n",
      "2018-09-10 07:49:30,583 - Epoch[0] Batch [2500]\tSpeed: 458.54 samples/sec\taccuracy=0.758906\ttop_k_accuracy_5=0.907891\n",
      "2018-09-10 07:49:58,508 - Epoch[0] Batch [2550]\tSpeed: 458.41 samples/sec\taccuracy=0.765000\ttop_k_accuracy_5=0.914062\n",
      "2018-09-10 07:50:26,451 - Epoch[0] Batch [2600]\tSpeed: 458.14 samples/sec\taccuracy=0.760625\ttop_k_accuracy_5=0.910391\n",
      "2018-09-10 07:50:54,380 - Epoch[0] Batch [2650]\tSpeed: 458.35 samples/sec\taccuracy=0.764062\ttop_k_accuracy_5=0.909141\n",
      "2018-09-10 07:51:22,240 - Epoch[0] Batch [2700]\tSpeed: 459.50 samples/sec\taccuracy=0.756172\ttop_k_accuracy_5=0.906094\n",
      "2018-09-10 07:51:50,163 - Epoch[0] Batch [2750]\tSpeed: 458.48 samples/sec\taccuracy=0.758750\ttop_k_accuracy_5=0.907344\n",
      "2018-09-10 07:52:18,071 - Epoch[0] Batch [2800]\tSpeed: 458.69 samples/sec\taccuracy=0.756641\ttop_k_accuracy_5=0.909219\n",
      "2018-09-10 07:52:46,003 - Epoch[0] Batch [2850]\tSpeed: 458.33 samples/sec\taccuracy=0.760547\ttop_k_accuracy_5=0.911953\n",
      "2018-09-10 07:53:13,920 - Epoch[0] Batch [2900]\tSpeed: 458.56 samples/sec\taccuracy=0.760469\ttop_k_accuracy_5=0.909375\n",
      "2018-09-10 07:53:41,761 - Epoch[0] Batch [2950]\tSpeed: 459.80 samples/sec\taccuracy=0.758984\ttop_k_accuracy_5=0.909297\n",
      "2018-09-10 07:54:09,640 - Epoch[0] Batch [3000]\tSpeed: 459.19 samples/sec\taccuracy=0.751406\ttop_k_accuracy_5=0.907969\n",
      "2018-09-10 07:54:37,444 - Epoch[0] Batch [3050]\tSpeed: 460.44 samples/sec\taccuracy=0.755391\ttop_k_accuracy_5=0.913203\n",
      "2018-09-10 07:55:05,297 - Epoch[0] Batch [3100]\tSpeed: 459.61 samples/sec\taccuracy=0.767656\ttop_k_accuracy_5=0.912266\n",
      "2018-09-10 07:55:33,168 - Epoch[0] Batch [3150]\tSpeed: 459.35 samples/sec\taccuracy=0.762422\ttop_k_accuracy_5=0.911797\n",
      "2018-09-10 07:56:00,976 - Epoch[0] Batch [3200]\tSpeed: 460.64 samples/sec\taccuracy=0.759766\ttop_k_accuracy_5=0.910937\n",
      "2018-09-10 07:56:28,843 - Epoch[0] Batch [3250]\tSpeed: 459.39 samples/sec\taccuracy=0.765625\ttop_k_accuracy_5=0.914219\n",
      "2018-09-10 07:56:56,731 - Epoch[0] Batch [3300]\tSpeed: 459.02 samples/sec\taccuracy=0.755547\ttop_k_accuracy_5=0.909141\n",
      "2018-09-10 07:57:24,659 - Epoch[0] Batch [3350]\tSpeed: 458.38 samples/sec\taccuracy=0.768203\ttop_k_accuracy_5=0.912422\n",
      "2018-09-10 07:57:52,592 - Epoch[0] Batch [3400]\tSpeed: 458.28 samples/sec\taccuracy=0.764375\ttop_k_accuracy_5=0.910937\n",
      "2018-09-10 07:58:20,488 - Epoch[0] Batch [3450]\tSpeed: 458.90 samples/sec\taccuracy=0.769922\ttop_k_accuracy_5=0.911250\n",
      "2018-09-10 07:58:48,335 - Epoch[0] Batch [3500]\tSpeed: 459.72 samples/sec\taccuracy=0.763594\ttop_k_accuracy_5=0.910312\n",
      "2018-09-10 07:59:16,197 - Epoch[0] Batch [3550]\tSpeed: 459.47 samples/sec\taccuracy=0.755938\ttop_k_accuracy_5=0.908047\n",
      "2018-09-10 07:59:44,093 - Epoch[0] Batch [3600]\tSpeed: 458.89 samples/sec\taccuracy=0.759609\ttop_k_accuracy_5=0.908516\n",
      "2018-09-10 08:00:11,975 - Epoch[0] Batch [3650]\tSpeed: 459.13 samples/sec\taccuracy=0.764219\ttop_k_accuracy_5=0.912422\n",
      "2018-09-10 08:00:39,842 - Epoch[0] Batch [3700]\tSpeed: 459.38 samples/sec\taccuracy=0.761328\ttop_k_accuracy_5=0.911953\n",
      "2018-09-10 08:01:07,663 - Epoch[0] Batch [3750]\tSpeed: 460.13 samples/sec\taccuracy=0.758984\ttop_k_accuracy_5=0.908750\n",
      "2018-09-10 08:01:35,448 - Epoch[0] Batch [3800]\tSpeed: 460.74 samples/sec\taccuracy=0.762266\ttop_k_accuracy_5=0.909922\n",
      "2018-09-10 08:02:03,354 - Epoch[0] Batch [3850]\tSpeed: 458.73 samples/sec\taccuracy=0.757500\ttop_k_accuracy_5=0.907109\n",
      "2018-09-10 08:02:31,293 - Epoch[0] Batch [3900]\tSpeed: 458.20 samples/sec\taccuracy=0.756953\ttop_k_accuracy_5=0.909609\n",
      "2018-09-10 08:02:59,252 - Epoch[0] Batch [3950]\tSpeed: 457.86 samples/sec\taccuracy=0.764453\ttop_k_accuracy_5=0.911328\n",
      "2018-09-10 08:03:27,141 - Epoch[0] Batch [4000]\tSpeed: 459.01 samples/sec\taccuracy=0.768594\ttop_k_accuracy_5=0.912813\n",
      "2018-09-10 08:03:55,078 - Epoch[0] Batch [4050]\tSpeed: 458.23 samples/sec\taccuracy=0.762656\ttop_k_accuracy_5=0.913672\n",
      "2018-09-10 08:04:22,872 - Epoch[0] Batch [4100]\tSpeed: 460.59 samples/sec\taccuracy=0.763047\ttop_k_accuracy_5=0.911250\n",
      "2018-09-10 08:04:50,681 - Epoch[0] Batch [4150]\tSpeed: 460.34 samples/sec\taccuracy=0.761016\ttop_k_accuracy_5=0.910000\n",
      "2018-09-10 08:05:18,482 - Epoch[0] Batch [4200]\tSpeed: 460.48 samples/sec\taccuracy=0.764219\ttop_k_accuracy_5=0.913516\n",
      "2018-09-10 08:05:46,244 - Epoch[0] Batch [4250]\tSpeed: 461.11 samples/sec\taccuracy=0.760859\ttop_k_accuracy_5=0.911641\n",
      "2018-09-10 08:06:13,991 - Epoch[0] Batch [4300]\tSpeed: 461.35 samples/sec\taccuracy=0.762813\ttop_k_accuracy_5=0.914844\n",
      "2018-09-10 08:06:41,784 - Epoch[0] Batch [4350]\tSpeed: 460.60 samples/sec\taccuracy=0.765391\ttop_k_accuracy_5=0.913594\n",
      "2018-09-10 08:07:09,683 - Epoch[0] Batch [4400]\tSpeed: 458.85 samples/sec\taccuracy=0.763281\ttop_k_accuracy_5=0.911719\n",
      "2018-09-10 08:07:37,605 - Epoch[0] Batch [4450]\tSpeed: 458.48 samples/sec\taccuracy=0.766953\ttop_k_accuracy_5=0.914219\n",
      "2018-09-10 08:08:05,480 - Epoch[0] Batch [4500]\tSpeed: 459.23 samples/sec\taccuracy=0.766328\ttop_k_accuracy_5=0.911875\n",
      "2018-09-10 08:08:33,377 - Epoch[0] Batch [4550]\tSpeed: 458.89 samples/sec\taccuracy=0.764531\ttop_k_accuracy_5=0.912578\n",
      "2018-09-10 08:09:01,272 - Epoch[0] Batch [4600]\tSpeed: 458.92 samples/sec\taccuracy=0.763281\ttop_k_accuracy_5=0.911719\n",
      "2018-09-10 08:09:29,167 - Epoch[0] Batch [4650]\tSpeed: 458.92 samples/sec\taccuracy=0.763750\ttop_k_accuracy_5=0.911406\n",
      "2018-09-10 08:09:57,044 - Epoch[0] Batch [4700]\tSpeed: 459.21 samples/sec\taccuracy=0.765156\ttop_k_accuracy_5=0.914141\n",
      "2018-09-10 08:10:24,981 - Epoch[0] Batch [4750]\tSpeed: 458.23 samples/sec\taccuracy=0.761563\ttop_k_accuracy_5=0.910859\n",
      "2018-09-10 08:10:52,910 - Epoch[0] Batch [4800]\tSpeed: 458.36 samples/sec\taccuracy=0.765938\ttop_k_accuracy_5=0.913203\n",
      "2018-09-10 08:11:20,841 - Epoch[0] Batch [4850]\tSpeed: 458.32 samples/sec\taccuracy=0.769766\ttop_k_accuracy_5=0.912266\n",
      "2018-09-10 08:11:48,725 - Epoch[0] Batch [4900]\tSpeed: 459.10 samples/sec\taccuracy=0.766172\ttop_k_accuracy_5=0.909844\n",
      "2018-09-10 08:12:16,618 - Epoch[0] Batch [4950]\tSpeed: 458.94 samples/sec\taccuracy=0.767422\ttop_k_accuracy_5=0.911328\n",
      "2018-09-10 08:12:44,539 - Epoch[0] Batch [5000]\tSpeed: 458.50 samples/sec\taccuracy=0.762344\ttop_k_accuracy_5=0.914844\n",
      "2018-09-10 08:12:46,787 - Epoch[0] Train-accuracy=0.735352\n",
      "2018-09-10 08:12:46,789 - Epoch[0] Train-top_k_accuracy_5=0.895508\n",
      "2018-09-10 08:12:46,790 - Epoch[0] Time cost=2795.914\n",
      "2018-09-10 08:12:49,691 - Saved checkpoint to \"model/se-resnext-wpretrain-imagenet-50-0-0001.params\"\n",
      "2018-09-10 08:13:18,844 - Epoch[0] Validation-accuracy=0.757892\n",
      "2018-09-10 08:13:18,847 - Epoch[0] Validation-top_k_accuracy_5=0.919942\n",
      "2018-09-10 08:13:47,276 - Epoch[1] Batch [50]\tSpeed: 466.03 samples/sec\taccuracy=0.757583\ttop_k_accuracy_5=0.906097\n",
      "2018-09-10 08:14:14,988 - Epoch[1] Batch [100]\tSpeed: 461.93 samples/sec\taccuracy=0.761250\ttop_k_accuracy_5=0.908750\n",
      "2018-09-10 08:14:42,802 - Epoch[1] Batch [150]\tSpeed: 460.26 samples/sec\taccuracy=0.754141\ttop_k_accuracy_5=0.907344\n",
      "2018-09-10 08:15:10,707 - Epoch[1] Batch [200]\tSpeed: 458.75 samples/sec\taccuracy=0.758984\ttop_k_accuracy_5=0.907109\n",
      "2018-09-10 08:15:38,584 - Epoch[1] Batch [250]\tSpeed: 459.21 samples/sec\taccuracy=0.755703\ttop_k_accuracy_5=0.908906\n",
      "2018-09-10 08:16:06,461 - Epoch[1] Batch [300]\tSpeed: 459.21 samples/sec\taccuracy=0.759766\ttop_k_accuracy_5=0.909531\n",
      "2018-09-10 08:16:34,313 - Epoch[1] Batch [350]\tSpeed: 459.64 samples/sec\taccuracy=0.753203\ttop_k_accuracy_5=0.904687\n",
      "2018-09-10 08:17:02,197 - Epoch[1] Batch [400]\tSpeed: 459.09 samples/sec\taccuracy=0.756328\ttop_k_accuracy_5=0.906094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4ad885784ad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mallow_missing\u001b[0m      \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m          \u001b[0;34m=\u001b[0m\u001b[0;34m'nag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moptimizer_params\u001b[0m   \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr_scheduler'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr_sch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# logging.info(\"top-1 and top-5 acc is {}\".format(model.score(X = val,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)\u001b[0m\n\u001b[1;32m    494\u001b[0m                     \u001b[0mend_of_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/module.py\u001b[0m in \u001b[0;36mupdate_metric\u001b[0;34m(self, eval_metric, labels)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mTypically\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sync_params_from_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36mupdate_metric\u001b[0;34m(self, eval_metric, labels)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mlabels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0meval_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bind_ith_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate_dict\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate_dict\u001b[0;34m(self, label, pred)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data         = train,\n",
    "    eval_data          = val,\n",
    "    eval_metric        = ['acc'] if args.data_type=='cifar10' else\n",
    "                         ['acc', mx.metric.create('top_k_accuracy', top_k = 5)],\n",
    "    kvstore            = kv,\n",
    "    batch_end_callback = mx.callback.Speedometer(args.batch_size, args.frequent),\n",
    "    epoch_end_callback = checkpoint,\n",
    "    num_epoch          = 200 if args.data_type == \"cifar10\" else 125,\n",
    "    begin_epoch        = 0,\n",
    "    arg_params         = arg_params,\n",
    "    aux_params         = aux_params,\n",
    "    allow_missing      =True,\n",
    "    optimizer          ='nag',\n",
    "    optimizer_params   ={'learning_rate':args.lr, 'momentum':args.mom, 'wd':args.wd, 'lr_scheduler': lr_sch}\n",
    ")\n",
    "# logging.info(\"top-1 and top-5 acc is {}\".format(model.score(X = val,\n",
    "#               eval_metric = ['acc', mx.metric.create('top_k_accuracy', top_k = 5)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
